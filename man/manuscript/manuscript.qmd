---
title: "quicR: An R Package for Real-Time Quaking Induced Conversion (RT-QuIC) Assays"
author:
    - name: 
        given: Gage
        family: Rowden
        id: GR
        orcid: 0000-0002-7517-0480
        email: rowde002@umn.edu
        affiliation:
          name: University of Minnesota
          city: Saint Paul
          state: MN
        roles:
          Conceptualization
          Methodology
          Software
          Validation
          Formal analysis
          Investigation
          Resources
          Data curation
          Writing--original draft preparation
          Writing--review and editing
          Visualization
          Supervision
          Prject administration
        corresponding: true
    - name:
        given: Peter
        family: Larsen
        id: PL
        orcid: 0000-0000-0000-0000
        email: plarsen@umn.edu
        affiliation:
          name: University of Minnesota
          city: Saint Paul
          state: MN
        roles:
          Supervision
          Project administration
          Funding
      
abstract: Real-time quaking induced conversion (RT-QuIC) has quickly become an emerging diagnostic tool for protein misfolding disorders such as Creutzfeldt-Jakob disease and Parkinson's disease. Given that the technology is still relatively new, academic and industry standards have yet to be established. 'quicR' was developed to fill this lack of standardization by providing functions for data curation, analysis, and vizualiztion. 
keywords: quicR, R package, RT-QuIC, prion, CJD, Parkinson's
format: 
  pdf:
    papersize: letter
    documentclass: article
    fontsize: 12pt
    geometry:
      - top=30mm
      - right=30mm
      - bottom=30mm
      - left=30mm
    include-in-header: 
      - text: \usepackage{tabularray}
      - text: \usepackage{float}
      - text: \floatplacement{table}{H}
mainfont: Calibri
bibliography: references.bib
bibliographystyle: apa
---
```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(quicR)
library(dplyr)
library(kableExtra)
library(readxl)
library(readr)
library(ggplot2)
library(reshape2)

file <- "../../inst/extdata/input_files/test2.xlsx"
file_384 <- "../../inst/extdata/input_files/test384.xlsx"
sample_file <- "../../inst/extdata/BMG_formatting/plate_layout.csv"
path <- "../../inst/extdata/BMG_formatting"
```


# Introduction
Real-time quaking induced conversion is a diagnostic assay that converts recombinant protein substrate into a misfolded aggregate in the presence of a misfolded seed [@Atarashi2011]. Given the recent development and novelty of the assay, academic and industry standards for analysis have yet to be established. 'quicR' is an attempt to provide an open-source library dedicated to RT-QuIC assays.

While standard metrics for determining a diagnosis have not been universally established, there are certain metrics that many research groups have found useful. These include time-to-threshold (TtT)[@Orru2015], rate of amyloid formation (RAF)[@Gallups2022], maxpoint ratio (MPR)[@Rowden2023], and maximum slope (MS)[@Henderson2015]. All together, these metrics provide insight into the general kinetics of an RT-QuIC reaction, and can be used together to draw a more robust diagnostic decision.

quicR also provides visualization options using ggplot2 [@ggplot2016] on the backend. Figures generated by quicR functions can be manipulated using the ggplot2 "+" syntax.

# Methods
This package requires the following dependencies: dplyr, ggplot2, janitor, openxlsx, readxl, reshape2, slider, stats, stringr, and tidyr. Because the MARS software (BMG Labtech, Ortenberg, Germany) exports data as an Excel workbook, the packages, openxlsx and readxl, were fundamental to performing downstream handling. The tidyverse packages (dplyr, ggplot2, stringr, and tidyr), were vital for writing easy-to-read code and for data visualization. The janitor package has useful functions for performing quick data cleaning.

# Development
The quicR package was developed to address the need for efficient data conversion and analysis of RT-QuIC data. The functions were designed with usability and reproducibility in mind, ensuring compatibility between multiple labs. Currently, the package accepts data exported from the proprietary MARS software (BMG Labtech, Ortenberg, Germany) as an Excel workbook.

The functionality in this package revolves around data curation, metric calculations, and visualization. 

# Implementation

## Input of Sample IDs into MARS
MARS allows input of a TXT file containing sample IDs, dilution factors, and their well locations. This file is uniquely formatted, and not easily reproduced manually. The function, "BMG_format", allows for input of a CSV file containing the plate layout (see @tbl-layout for proper formatting), and exports the formatted TXT file.

<!-- ### Example CSV File Plate Layout -->
:::{#tbl-layout tbl-pos="ht" tbl-cap-location="bottom"}
```{=latex}
\begin{tblr}{
  colspec = {|c|cccccccccccc|}, 
  row{1} = {font=\bfseries}, 
  column{1} = {font=\bfseries}, 
  rowhead = 1
}
  \hline
   & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 \\ 
  \hline
  A & P & S01 & S02 & S03 & S04 & S05 & S06 & S07 & S08 & S09 & S10 & S11 \\ 
  B & P & S01 & S02 & S03 & S04 & S05 & S06 & S07 & S08 & S09 & S10 & S11 \\ 
  C & P & S01 & S02 & S03 & S04 & S05 & S06 & S07 & S08 & S09 & S10 & S11 \\ 
  D & P & S01 & S02 & S03 & S04 & S05 & S06 & S07 & S08 & S09 & S10 & S11 \\ 
  E & N & S01 & S02 & S03 & S04 & S05 & S06 & S07 & S08 & S09 & S10 & S11 \\ 
  F & N & S01 & S02 & S03 & S04 & S05 & S06 & S07 & S08 & S09 & S10 & S11 \\ 
  G & N & S01 & S02 & S03 & S04 & S05 & S06 & S07 & S08 & S09 & S10 & S11 \\ 
  H & N & S01 & S02 & S03 & S04 & S05 & S06 & S07 & S08 & S09 & S10 & S11 \\ 
  \hline
\end{tblr}
```
Example CSV file plate layout for input into the "BMG_format" function. The top left corner should be cell "A1" in the file. The top numbered row and the left-most lettered column should never be altered.
:::

\newpage

### Formatted Plate Layout for MARS Input
The function, "BMG_format", includes the logical argument "write_file". If TRUE, it will create a TXT file. The path can be given to the "save_path" argument, and the file name can be supplied to the "save_name" argument. The text file will be formatted as follows, and can be imported into MARS.

```{r, eval=FALSE, message=FALSE}
BMG_format(sample_file, write_file = TRUE)
```
```
A1  P      P
B1  P      P
C1  P      P
D1  P      P
E1  N      N
F1  N      N
G1  N      N
H1  N      N
A2  X1     S01
B2  X1     S01
C2  X1     S01
D2  X1     S01
E2  X1     S01
F2  X1     S01
G2  X1     S01
H2  X1     S01
```

## Data Cleaning and Transformation
The MARS software (BMG Labtech, Ortenberg, Germany) exports real-time data as an Excel workbook. Typically, the first sheet in the workbook will include microplate views of both raw data and metadata. The two tables that are most relevant on this sheet are the "Sample IDs" and the "Dilutions" tables (if included). For much of the downstream analysis, it is crucial the the "Sample IDs" table was exported. If there is no table, the user can simply add it manually.

### Retrieving Metadata
The metadata is defined as either sample-dependent or -independent. Sample-dependent metadata includes information such as sample IDs and dilution factors, whereas sample-independent metadata includes the date, time, reaction ID, etc.

The dependent metadata can be retrieved using the "organize_tables" and "convert_tables" functions. The former returns a list of tables, and the latter converts each table into a column in a single data frame. See @tbl-tables for example outputs of organize_tables.

```{r, echo=FALSE, message=FALSE}
tabs <- organize_tables(file)[-2]
```
```{r, eval=FALSE}
organize_tables(file)
```

```{r, echo=FALSE, as.is=TRUE}
#| label: tbl-tables
#| tbl-cap: Sample IDs and Dilution Factors
rename <- function(x) {
  names(x) <- 1:12
  rownames(x) <- LETTERS[1:8]
  return(x)
}

tabs$`Sample IDs` %>%
  as.data.frame() %>%
  rename() %>%
  kable(
    format = "latex",
    booktabs = TRUE,
    linesep = "",
    align = rep("c", 12)
  ) %>%
  column_spec(1, border_left = TRUE, border_right = TRUE, bold = TRUE) %>%
  column_spec(13, border_right = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  kable_styling(full_width = TRUE, font_size = 10)

tabs$Dilutions %>%
  as.data.frame() %>%
  rename() %>%
  kable(
    format = "latex",
    booktabs = TRUE,
    linesep = "",
    align = rep("c", 12)
  ) %>%
  column_spec(1, border_left = TRUE, border_right = TRUE, bold = TRUE) %>%
  column_spec(13, border_right = TRUE) %>%
  row_spec(0, bold = TRUE) %>%
  kable_styling(full_width = TRUE, font_size = 10)
```

```{r, eval=FALSE}
organize_tables(file) %>% convert_tables()
```
```{r, echo=FALSE, message=FALSE}
tabs <- convert_tables(tabs)
tabs %>% head(12) %>% kable(row.names = FALSE)
```

\newpage

#### Sample Locations
Samples locations can be extracted based on their well ID. The "get_sample_locations" function accepts additional arguments if dilution factors were exported from MARS. The "dilution_fun" argument will supply a function for transforming the dilution factors (e.g. if the user would want to perform a log transformation).
```{r, eval=FALSE}
get_sample_locations(
  file, 
  dilution_bool = TRUE, 
  dilution_fun = function(x) 
    -log10(x), 
  sep = " "
)
```
```{r, echo=FALSE}
get_sample_locations(
  file, dilution_bool = TRUE, dilution_fun = function(x) -log10(x), sep = " "
) %>%
  head(12) %>%
  kable(row.names = FALSE, align = c("c", "c"))
```

\newpage

#### Sample-Independent Metadata
The independent metadata can be retrieved using the "get_meta" function. This data is included in the header of the excel workbook.

```{r, eval=FALSE}
get_meta(file)
```
```{r, echo=FALSE, message=FALSE}
get_meta(file) %>%
  mutate_at("Meta_info", ~gsub("\\\\", "/", .)) %>%
  kable(row.names = FALSE)
```

\newpage

### Retrieving and Manipulating Raw Data
The raw data is typically found on the second sheet of the Excel workbook. The raw real-time data can be retrieved using the "get_real" function. The logical argument, "ordered", indicates whether the user would prefer the columns to be ordered by well or by sample ID. By default, it is FALSE which will order the data by well. This should almost always be the case for easier integration with other downstream functions. Additionally, since there can be more than one instance of real-time data (depending on if the user added some calculations in MARS), "get_real" returns a list of dataframes. Therefore, the output should be indexed to access the data frame of interest.

#### Retrieve Raw Data
```{r, eval=FALSE}
get_real(file)[[1]]
```
```{r, echo=FALSE}
columns <- 8
df_ <- get_real(file, ordered = FALSE)[[1]] %>% as.data.frame()
df_[1:11, 1:columns] %>% kable(row.names = FALSE, align = rep("c", columns))
```

\newpage

#### Transpose Raw Data
This data is structured such that each sample is its own column (variable) and each row (observation) is a time point. While this format is technically correct, a transposed format is more ideal for some downstream manipulation. This operation is performed using the function, "transpose_real". After transposition, each time point is an individual column (variable), and each sample is an individual row (observation).

```{r, eval=FALSE}
get_real(file)[[1]] %>% transpose_real()
```
```{r, echo=FALSE}
columns <- 12
transpose_real(df_)[1:7, 1:columns] %>% 
  kable(row.names = FALSE, align = rep("c", columns))
```

#### Normalize Raw Data
The function "normalize_RFU" will convert the raw data into a background normalized data set. The function includes two additional arguments, "bg_cycle" (the cycle which will be used as the background fluorescence value) and "transposed" (if FALSE, will make a call to the "transpose_real" function). Note that the fourth time point is all "1's" since this was designated the background cycle.

```{r, eval=FALSE}
get_real(file)[[1]] %>% normalize_RFU(transposed = FALSE)
```
```{r, echo=FALSE, message=FALSE}
df_norm <- normalize_RFU(df_, bg_cycle = 4, transposed = FALSE)

df_norm[1:7, 1:columns] %>%
  mutate_at(2:ncol(.), ~round(as.numeric(.), 2)) %>%
  kable(row.names = FALSE, align = rep("c", columns))

df_norm <- df_norm %>%
  mutate(`Sample IDs` = tabs$`Sample IDs`)
```

## Calculations
There are three analytical metrics with dedicated functions: time-to-threshold (TtT), maxpoint ratio (MPR), and maximum slope (MS). The rate of amyloid formation does not have a designated function since it is simply the inverse of the time-to-threshold. Each function below accepts input from the "transpose_real" or the "normalize_RFU" functions. See @tbl-metrics for an example of the output of these functions.

### Thresholds
Many publications have different methods of determining thresholds. By and large, the most popular method is to take the average background fluorescence of the entire plate and add some multiple of standard deviations. The quicR package provides the "calculate_threshold" function for this purpose. A value can be provided as the optional argument, "multiplier", which will be applied to the standard deviation.
```{r, eval=FALSE}
get_real(file)[[1]] %>% calculate_threshold(multiplier = 10)
```
```{r, echo=FALSE}
calculate_threshold(df_, multiplier = 10)
```


### Time-to-threshold
TtT is calculated using the "calculate_TtT" function. The function must be supplied a threshold; default value is 2 (i.e. twice the background fluorescence if the data is normalized). A starting column should also be given as an integer; default value is 3. This is essentially asking how many columns of metadata are included before the fluorescence reads begin. 

TtT is calculated by iterating through each row and checking if a value is greater than the threshold. If the value is greater, the slope of the previous time-point to the current time-point is calculated, and the time intersection of the current read is returned.

### Maxpoint Ratio
MPR is calculated by the "calculate_MPR" function. Data must be normalized in order to derive this metric. In a normalized data set, the MPR is simply the maximum value achieved during the run. Raw data can be passed to this function, but the argument, "data_is_norm", must be set to TRUE. This will pass the raw data to "normalize_RFU" before calculating the MPR values.

### Maximum Slope
MS is calculated by the "calculate_MS" function. The function iterates through each row using a rolling window which can be adjusted (default value is 3). Given the window size, the slope is calcualated based on change in fluorescence divided by the range of the window. The MS is simply the largest slope value recorded. The units are typically reported as $\Delta$RFU/s.

\newpage

```{r, eval=FALSE}
#| label: tbl-metrics
#| tbl-cap: Calculated metrics
#| tbl-cap-location: bottom

samples <- tabs$`Sample IDs`
dilutions <- tabs$Dilutions

df_norm <- get_real(file) %>% normalize_RFU()

data.frame("Sample IDs" = samples, check.names = FALSE) %>%
  mutate(
    Dilutions = -log10(dilutions),
    # Maxpoint Ratio
    MPR = calculate_MPR(df_norm, start_col = 3, data_is_norm = TRUE),
    # Max Slope
    MS = calculate_MS(df_norm, data_is_norm = TRUE),
    # Time to Threshold
    TtT = calculate_TtT(df_norm, threshold = 2, start_col = 3),
    # Rate of Amyloid Formation
    RAF = 1 / TtT
  )
```

```{r, echo=FALSE}
samples <- tabs$`Sample IDs`
dilutions <- tabs$Dilutions %>% na.omit() %>% as.numeric()

df_analyzed <- data.frame("Sample IDs" = samples, check.names = FALSE) %>%
  mutate(
    Dilutions = -log10(dilutions),
    # Maxpoint Ratio
    MPR = calculate_MPR(df_norm, start_col = 3, data_is_norm = TRUE),
    # Max Slope
    MS = calculate_MS(df_norm, data_is_norm = TRUE),
    # Time to Threshold
    TtT = calculate_TtT(df_norm, threshold = 2, start_col = 3),
    # Rate of Amyloid Formation
    RAF = 1 / TtT
  )

df_analyzed%>%
  head(12) %>%
  kable(row.names = FALSE, align = rep("c", ncol(df_analyzed)))
```

\newpage

## Visualization

### Plate View
The "plate_view" function requires *un-transposed* data and sample locations as arguments. It also has an argument for plate type which will either be 96 or 384.
```{r, warning=FALSE}
#| fig-width: 12
#| fig-height: 8
sample_locations <- get_sample_locations(
  file, 
  dilution_bool = TRUE,
  dilution_fun = function(x) -log10(x)
)

plate_view(df_, sample_locations)
```

\newpage

### Summary Plots
```{r, warning=FALSE, message=FALSE}
#| fig-width: 8
#| fig-height: 6.5
df_analyzed %>%
  melt(id.vars = c("Sample IDs", "Dilutions")) %>%
  mutate_at("Dilutions", as.factor) %>%
  
  ggplot(aes(`Sample IDs`, value, fill = Dilutions)) +
    geom_boxplot() +
    facet_wrap(~variable, scales = "free") +
    theme(
      legend.position = "bottom",
      strip.text = element_text(face = "bold"),
      axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1),
      axis.title = element_blank()
    )
```

\newpage

# Usage

## Installation
```{r, eval=FALSE}
# Latest CRAN release
install.packages("quicR")

# Development version
devtools::install_github("gage1145/quicR")
```


# Validation & Performance

# Discussion

# Conclusion
quicR provides improved and standardized methods for analyzing RT-QuIC data. 

# Acknowledgments

# References
::: {#refs}
:::

